{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8576c935-87fc-4993-9ef1-aa01b250293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e05a971-8ab0-4d3b-919b-2b6bb343af2e",
   "metadata": {},
   "source": [
    "# Goal is to create a NN to take trigrams or more\n",
    "1. Create X with input letters, create Y with output. Need to create itos and stoi\n",
    "3. Create C which is a lookup table of dimension 2\n",
    "4. Create a NN that takes that and gives our probabilities of next letter\n",
    "5. calculate loss and reduce loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2e9119c3-8d0e-4707-b70a-ec33d840890c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia']\n"
     ]
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(words[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1ed987f9-b337-4ec1-a355-ccf8fa5f6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create itos and stoi\n",
    "chars = sorted(set(''.join(words)))\n",
    "itos = {i+1: ch for i, ch in enumerate(chars)}\n",
    "itos[0] = '.'\n",
    "stoi = {ch: i for i, ch in itos.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "05447c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182484, 3]) torch.Size([182484])\n",
      "torch.Size([22869, 3]) torch.Size([22869])\n",
      "torch.Size([22793, 3]) torch.Size([22793])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  for w in words:\n",
    "\n",
    "    #print(w)\n",
    "\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2e52b930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17697\n"
     ]
    }
   ],
   "source": [
    "emb_size = 10\n",
    "hidden_size = 300\n",
    "\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, emb_size), generator=g)\n",
    "W1 = torch.randn((block_size * emb_size, hidden_size), generator=g)\n",
    "B1 = torch.randn((hidden_size), generator=g)\n",
    "W2 = torch.randn((hidden_size, 27), generator=g)\n",
    "B2 = torch.randn((27), generator=g)\n",
    "\n",
    "parameters = [C, W1, B1, W2, B2]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "95221581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> 27.76041030883789\n",
      "1000 --> 7.383129596710205\n",
      "2000 --> 4.967247009277344\n",
      "3000 --> 5.519577503204346\n",
      "4000 --> 3.9406542778015137\n",
      "5000 --> 3.1676886081695557\n",
      "6000 --> 3.921692371368408\n",
      "7000 --> 2.874091863632202\n",
      "8000 --> 4.2571001052856445\n",
      "9000 --> 3.5421793460845947\n",
      "10000 --> 2.91940975189209\n",
      "11000 --> 3.549651622772217\n",
      "12000 --> 3.01814341545105\n",
      "13000 --> 2.8955399990081787\n",
      "14000 --> 3.216179370880127\n",
      "15000 --> 3.2225229740142822\n",
      "16000 --> 2.525787830352783\n",
      "17000 --> 2.3461453914642334\n",
      "18000 --> 2.481290817260742\n",
      "19000 --> 3.1850271224975586\n",
      "20000 --> 2.931797981262207\n",
      "21000 --> 2.186738967895508\n",
      "22000 --> 2.3855080604553223\n",
      "23000 --> 2.3878979682922363\n",
      "24000 --> 2.40989089012146\n",
      "25000 --> 2.6075611114501953\n",
      "26000 --> 2.828981399536133\n",
      "27000 --> 2.7231318950653076\n",
      "28000 --> 2.896237850189209\n",
      "29000 --> 2.7958455085754395\n",
      "30000 --> 3.064750909805298\n",
      "31000 --> 2.4138758182525635\n",
      "32000 --> 2.2294819355010986\n",
      "33000 --> 2.2644565105438232\n",
      "34000 --> 2.461005210876465\n",
      "35000 --> 2.371458053588867\n",
      "36000 --> 2.7983338832855225\n",
      "37000 --> 2.257885217666626\n",
      "38000 --> 2.0169310569763184\n",
      "39000 --> 2.413611888885498\n",
      "40000 --> 1.8665311336517334\n",
      "41000 --> 2.2366180419921875\n",
      "42000 --> 2.3084051609039307\n",
      "43000 --> 2.547513008117676\n",
      "44000 --> 2.5282039642333984\n",
      "45000 --> 2.687391996383667\n",
      "46000 --> 2.3141725063323975\n",
      "47000 --> 2.4628546237945557\n",
      "48000 --> 2.4343161582946777\n",
      "49000 --> 2.6461470127105713\n",
      "50000 --> 2.179825782775879\n",
      "51000 --> 2.1475911140441895\n",
      "52000 --> 1.8981692790985107\n",
      "53000 --> 2.290872573852539\n",
      "54000 --> 2.411926031112671\n",
      "55000 --> 3.125704526901245\n",
      "56000 --> 2.43026065826416\n",
      "57000 --> 2.437203884124756\n",
      "58000 --> 2.426431894302368\n",
      "59000 --> 2.9191501140594482\n",
      "60000 --> 2.088427782058716\n",
      "61000 --> 2.7881107330322266\n",
      "62000 --> 2.1315934658050537\n",
      "63000 --> 2.3188841342926025\n",
      "64000 --> 2.3316080570220947\n",
      "65000 --> 1.8200492858886719\n",
      "66000 --> 2.343535900115967\n",
      "67000 --> 2.34354305267334\n",
      "68000 --> 2.2402689456939697\n",
      "69000 --> 2.541243314743042\n",
      "70000 --> 2.3663065433502197\n",
      "71000 --> 2.1939120292663574\n",
      "72000 --> 2.339308738708496\n",
      "73000 --> 1.9151136875152588\n",
      "74000 --> 2.7252557277679443\n",
      "75000 --> 1.7335840463638306\n",
      "76000 --> 2.2871391773223877\n",
      "77000 --> 2.00600528717041\n",
      "78000 --> 2.361809253692627\n",
      "79000 --> 1.7952996492385864\n",
      "80000 --> 2.6577162742614746\n",
      "81000 --> 2.830873489379883\n",
      "82000 --> 2.4667394161224365\n",
      "83000 --> 2.369049549102783\n",
      "84000 --> 2.0560286045074463\n",
      "85000 --> 2.3253471851348877\n",
      "86000 --> 2.3489694595336914\n",
      "87000 --> 2.663635015487671\n",
      "88000 --> 2.5057990550994873\n",
      "89000 --> 1.9989328384399414\n",
      "90000 --> 2.1958794593811035\n",
      "91000 --> 2.297393798828125\n",
      "92000 --> 2.2760705947875977\n",
      "93000 --> 2.361428737640381\n",
      "94000 --> 2.3589422702789307\n",
      "95000 --> 2.0924391746520996\n",
      "96000 --> 1.6054022312164307\n",
      "97000 --> 2.494917154312134\n",
      "98000 --> 2.0294675827026367\n",
      "99000 --> 2.2772812843322754\n",
      "100000 --> 2.597991943359375\n",
      "101000 --> 2.7866506576538086\n",
      "102000 --> 2.0657107830047607\n",
      "103000 --> 1.7653191089630127\n",
      "104000 --> 2.424605369567871\n",
      "105000 --> 2.03249454498291\n",
      "106000 --> 2.3583343029022217\n",
      "107000 --> 2.4721503257751465\n",
      "108000 --> 2.113027811050415\n",
      "109000 --> 2.5703134536743164\n",
      "110000 --> 2.224304676055908\n",
      "111000 --> 2.324570894241333\n",
      "112000 --> 2.3318686485290527\n",
      "113000 --> 2.905750274658203\n",
      "114000 --> 2.2497150897979736\n",
      "115000 --> 2.6400349140167236\n",
      "116000 --> 2.7464680671691895\n",
      "117000 --> 2.2066638469696045\n",
      "118000 --> 2.5109729766845703\n",
      "119000 --> 2.198920488357544\n",
      "120000 --> 2.184171438217163\n",
      "121000 --> 2.5028252601623535\n",
      "122000 --> 2.1015713214874268\n",
      "123000 --> 2.347659111022949\n",
      "124000 --> 2.081404209136963\n",
      "125000 --> 2.499147415161133\n",
      "126000 --> 2.675447463989258\n",
      "127000 --> 2.699413776397705\n",
      "128000 --> 2.8858439922332764\n",
      "129000 --> 2.3339624404907227\n",
      "130000 --> 2.593259811401367\n",
      "131000 --> 2.251373052597046\n",
      "132000 --> 2.5774483680725098\n",
      "133000 --> 2.054250717163086\n",
      "134000 --> 2.440803050994873\n",
      "135000 --> 2.540361166000366\n",
      "136000 --> 2.4248621463775635\n",
      "137000 --> 2.4865875244140625\n",
      "138000 --> 2.0577504634857178\n",
      "139000 --> 2.240893602371216\n",
      "140000 --> 2.366887331008911\n",
      "141000 --> 2.230407953262329\n",
      "142000 --> 1.9426156282424927\n",
      "143000 --> 2.2557225227355957\n",
      "144000 --> 2.1018126010894775\n",
      "145000 --> 2.1987507343292236\n",
      "146000 --> 2.396841049194336\n",
      "147000 --> 2.2969579696655273\n",
      "148000 --> 2.382817029953003\n",
      "149000 --> 2.1802937984466553\n",
      "150000 --> 2.3412230014801025\n",
      "151000 --> 1.9705623388290405\n",
      "152000 --> 2.473444700241089\n",
      "153000 --> 2.1502602100372314\n",
      "154000 --> 2.7462782859802246\n",
      "155000 --> 2.418044090270996\n",
      "156000 --> 2.583434820175171\n",
      "157000 --> 2.32909893989563\n",
      "158000 --> 2.162907838821411\n",
      "159000 --> 2.567598581314087\n",
      "160000 --> 2.5259413719177246\n",
      "161000 --> 2.4500606060028076\n",
      "162000 --> 1.9961618185043335\n",
      "163000 --> 2.2188479900360107\n",
      "164000 --> 2.4011423587799072\n",
      "165000 --> 2.1158347129821777\n",
      "166000 --> 2.510286569595337\n",
      "167000 --> 2.334411382675171\n",
      "168000 --> 2.405268907546997\n",
      "169000 --> 2.3136067390441895\n",
      "170000 --> 2.1368680000305176\n",
      "171000 --> 1.8663984537124634\n",
      "172000 --> 2.253227710723877\n",
      "173000 --> 1.9261209964752197\n",
      "174000 --> 2.1792399883270264\n",
      "175000 --> 2.2136282920837402\n",
      "176000 --> 2.4226582050323486\n",
      "177000 --> 2.140424966812134\n",
      "178000 --> 2.2930526733398438\n",
      "2.2930526733398438\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 178001\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    # forward pass\n",
    "    #minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "\n",
    "    emb = C[Xtr[ix]]\n",
    "    h = torch.tanh(emb.view(-1, block_size * emb_size) @ W1 + B1)\n",
    "    logits = h @ W2 + B2\n",
    "    loss = F.cross_entropy(logits, Ytr[ix])\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"{i} --> {loss.item()}\")\n",
    "              \n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "    #if i < int(n_epochs * 0.25):\n",
    "    #    lr = 0.1\n",
    "    #elif i < int(n_epochs * 0.75):\n",
    "    #    lr = 0.01\n",
    "    #else:\n",
    "    #    lr = 0.0001\n",
    "    lr = 0.1 if i < (n_epochs * 0.8) else 0.01\n",
    "    for p in parameters:\n",
    "        p.data -= 0.01 * p.grad \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5df7c94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3074467182159424\n"
     ]
    }
   ],
   "source": [
    "#beat xDev of 2.17 loss\n",
    "emb = C[Xdev]\n",
    "h = torch.tanh(emb.view(-1, block_size * emb_size) @ W1 + B1)\n",
    "\n",
    "logits = h @ W2 + B2\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "6b9124e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3086841106414795\n"
     ]
    }
   ],
   "source": [
    "emb = C[Xte]\n",
    "h = torch.tanh(emb.view(-1, block_size * emb_size) @ W1 + B1)\n",
    "logits = h @ W2 + B2\n",
    "loss = F.cross_entropy(logits, Yte)\n",
    "print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnn_course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
